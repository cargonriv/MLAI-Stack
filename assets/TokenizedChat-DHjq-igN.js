import{j as e}from"./chunk-hK1J5FH5.js";import{r as s}from"./chunk-jyyxJnsv.js";import{b as t,z as n,e as a,o as r,f as i,g as o,y as l,L as c,C as d,M as x,F as m,X as h,i as u,B as p,I as g,Z as j,j as f,J as k,U as N,A as w,T as b,K as y,N as v,H as T,h as z,w as I,O as C,x as P,s as D,D as S}from"./index-Cs7pq2m6.js";import{_ as A}from"./chunk-DxTKSm-D.js";import"./transformers.web.js-B2xmzSE8.js";import"./chunk-BNd5y9io.js";const G=({isOpen:T,onToggle:z})=>{const[I,C]=s.useState([]),[P,D]=s.useState(""),[S,G]=s.useState(!1),[E,M]=s.useState(!1),[R,_]=s.useState("loading"),[L,H]=s.useState(!1),$=s.useRef(null),B=s.useRef(null),F=s.useRef(null),O=s.useRef(!1);s.useEffect(()=>(O.current=!0,()=>{O.current=!1}),[]),s.useEffect(()=>{if(!T||!O.current||"loading"!==R)return;const e=setTimeout(async()=>{try{const{AutoTokenizer:e}=await A(async()=>{const{AutoTokenizer:e}=await import("./transformers.web.js-B2xmzSE8.js");return{AutoTokenizer:e}},[]);if(!O.current)return;const s=await e.from_pretrained("Xenova/gpt-4");if(!O.current)return;const t="Hello! I can encode and decode tokens.";s.encode(t).map(e=>s.decode([e]));F.current=s,_("ready");const n="Hi! I'm your AI assistant with GPT-4 tokenization. I can show you exactly how text gets encoded into tokens and decoded back. Try sending a message to see the tokenization process in action!",a=s.encode(n),r=a.map(e=>s.decode([e]));C([{id:Date.now().toString(),content:n,sender:"bot",timestamp:new Date,tokens:a,tokenCount:a.length,decodedTokens:r}])}catch(e){O.current&&(_("error"),C([{id:Date.now().toString(),content:"I encountered an error loading the tokenizer, but I can still chat with you! The tokenization features won't be available in this session.",sender:"bot",timestamp:new Date,tokens:[],tokenCount:0}]))}},500);return()=>clearTimeout(e)},[T,R]),s.useEffect(()=>{if($.current){const e=$.current.querySelector("[data-radix-scroll-area-viewport]");e&&(e.scrollTop=e.scrollHeight)}},[I]),s.useEffect(()=>{T&&!E&&B.current&&setTimeout(()=>{var e;return null==(e=B.current)?void 0:e.focus()},100)},[T,E]);const Y=e=>{if("ready"!==R||!F.current||!e)return{tokens:[],decodedTokens:[],tokenCount:0};try{const s=F.current.encode(e),t=s.map(e=>F.current.decode([e]));return{tokens:s,decodedTokens:t,tokenCount:s.length}}catch(s){return{tokens:[],decodedTokens:[],tokenCount:0}}},W=(e,s)=>{const t=e.toLowerCase();if(t.includes("token")||t.includes("encode")||t.includes("decode")){return`${s.length>0?`Your message was encoded into ${s.length} tokens: [${s.slice(0,10).join(", ")}${s.length>10?"...":""}]. `:""}Tokenization is fascinating! Here's how it works:\n\n🔤 **Encoding**: Text → Numbers (tokens)\n🔢 **Processing**: AI models work with these numbers\n📝 **Decoding**: Numbers → Text output\n\nEach token represents a piece of text - could be a word, part of a word, or punctuation. GPT-4 uses a sophisticated tokenizer that handles multiple languages and special characters efficiently!`}if(t.includes("how")&&(t.includes("work")||t.includes("process")))return`Great question! Here's my processing pipeline:\n\n1️⃣ **Input Tokenization**: Your text gets encoded into ${s.length} tokens\n2️⃣ **Language Model**: I use DistilGPT-2 for text generation\n3️⃣ **Response Generation**: AI generates contextual responses\n4️⃣ **Output Tokenization**: My response gets tokenized too\n\nThis demonstrates the full NLP pipeline: tokenization → language model → generation → detokenization!`;if(t.includes("project")||t.includes("portfolio"))return`I'd love to tell you about Carlos's projects! Your ${s.length}-token question shows you're interested in his work.\n\n🚀 **Key Projects**:\n• SIDS Prediction Model (Healthcare AI)\n• Real-time Image Classification\n• Sentiment Analysis with BERT\n• This very chat system with GPT-4 tokenization + DistilGPT-2!\n\nEach project demonstrates different aspects of ML engineering - from data preprocessing to model deployment. Which one interests you most?`;if(t.includes("sids")||t.includes("capstone"))return"The SIDS Prediction Model is Carlos's flagship project! It processes physiological data through multiple tokenization and encoding stages:\n\n🏥 **Medical Data Pipeline**:\n• Sensor data → Feature tokens\n• Time series → Sequence encoding\n• Risk factors → Classification tokens\n• Predictions → Probability scores\n\nJust like how I tokenize text, the SIDS model tokenizes medical data to identify patterns that could save lives. It's a powerful example of AI for social good!";if(t.includes("technology")||t.includes("tech"))return`This portfolio showcases cutting-edge tech! Your message used ${s.length} tokens to ask about it.\n\n⚡ **Frontend**: React 18 + TypeScript\n🧠 **AI**: Hugging Face Transformers.js\n🔧 **Tokenization**: GPT-4 tokenizer\n🤖 **Generation**: DistilGPT-2 language model\n🎨 **UI**: Tailwind CSS + Shadcn/ui\n☁️ **Backend**: Supabase + Edge Functions\n\nEverything runs client-side for instant ML inference - no server round-trips needed!`;const n=[`[${s.length} tokens processed] I'm an AI assistant showcasing Carlos's ML portfolio. I use real tokenization and text generation models. What would you like to know about his projects, skills, or this chat system?`,`[Generated from ${s.length} input tokens] Thanks for your message! I demonstrate both tokenization and language generation. Carlos built this to show how modern NLP works. What aspect interests you most?`,`[Tokenized: ${s.length} tokens] Your message went through the full NLP pipeline - tokenization, language model processing, and generation. This showcases the same techniques Carlos uses in his ML projects. How can I help you learn more?`];return n[Math.floor(Math.random()*n.length)]},q=async()=>{const e=(null==P?void 0:P.trim())||"";if(!e)return;const{tokens:s,decodedTokens:t,tokenCount:n}=Y(e),a={id:Date.now().toString(),content:e,sender:"user",timestamp:new Date,tokens:s,tokenCount:n,decodedTokens:t};C(e=>[...e,a]),D(""),G(!0);try{const e=await(async(e,s)=>{if("ready"!==R||!F.current)return"I'm still loading my language capabilities. Please wait a moment and try again!";try{const{pipeline:t}=await A(async()=>{const{pipeline:e}=await import("./transformers.web.js-B2xmzSE8.js");return{pipeline:e}},[]),n=await t("text-generation","Xenova/distilgpt2",{max_new_tokens:100,do_sample:!0,top_k:50,top_p:.95,temperature:.7}),a=`You are an AI assistant for Carlos Gonzalez Rivera's ML portfolio. The user said: "${e}" (${s.length} tokens). Respond helpfully about his ML projects, skills, or tokenization. Keep it concise and informative.\n\nResponse:`;let r=(await n(a,{max_new_tokens:80,do_sample:!0,top_k:50,top_p:.95,temperature:.7,pad_token_id:50256}))[0].generated_text;return r=r.replace(a,"").trim(),r.length<20||!r.includes(" ")?W(e,s):`[Generated using ${s.length} input tokens] `+r}catch(t){return W(e,s)}})(a.content,a.tokens),{tokens:s,decodedTokens:t,tokenCount:n}=Y(e),r={id:(Date.now()+1).toString(),content:e,sender:"bot",timestamp:new Date,tokens:s,tokenCount:n,decodedTokens:t};C(e=>[...e,r]),(async(e,s)=>{try{const t={maxAdditionalTokens:30,timeoutMs:5e3,minCompletionLength:5,contentType:"conversational",languageCode:"en"},n=[{role:"user",content:s},{role:"assistant",content:e.content}],a=await v(e.content,n,"simple-fallback",t);a.wasCompleted&&a.completedText!==e.content&&C(s=>s.map(s=>{if(s.id===e.id){const{tokens:e,decodedTokens:t,tokenCount:n}=Y(a.completedText);return{...s,content:a.completedText,tokens:e,decodedTokens:t,tokenCount:n,completionInfo:{wasCompleted:!0,additionalTokensUsed:a.additionalTokensUsed,completionReason:a.completionReason,processingTimeMs:a.processingTimeMs}}}return s}))}catch(t){}})(r,a.content)}catch(r){const e="I apologize, but I encountered an error processing your message. Please try again!",{tokens:s,decodedTokens:t,tokenCount:n}=Y(e),a={id:(Date.now()+1).toString(),content:e,sender:"bot",timestamp:new Date,tokens:s,tokenCount:n,decodedTokens:t};C(e=>[...e,a])}finally{G(!1)}},K=Y(P);return T?e.jsxs(a,{className:r("fixed bottom-6 right-6 w-[420px] shadow-2xl border-purple-200 dark:border-purple-800 z-50 transition-all duration-300",E?"h-16":"h-[600px]"),children:[e.jsxs(i,{className:"pb-3 bg-gradient-to-r from-purple-600 to-pink-600 text-white rounded-t-lg",children:[e.jsxs("div",{className:"flex items-center justify-between",children:[e.jsxs(o,{className:"flex items-center gap-2 text-lg",children:[e.jsx(l,{className:"w-5 h-5"}),"Tokenized AI Chat","loading"===R&&e.jsx(c,{className:"w-4 h-4 animate-spin"})]}),e.jsxs("div",{className:"flex items-center gap-1",children:[e.jsx(t,{variant:"ghost",size:"icon",onClick:()=>H(!L),className:"w-8 h-8 text-white hover:bg-white/20",title:"Toggle token details",children:e.jsx(d,{className:"w-4 h-4"})}),e.jsx(t,{variant:"ghost",size:"icon",onClick:()=>M(!E),className:"w-8 h-8 text-white hover:bg-white/20",children:E?e.jsx(x,{className:"w-4 h-4"}):e.jsx(m,{className:"w-4 h-4"})}),e.jsx(t,{variant:"ghost",size:"icon",onClick:z,className:"w-8 h-8 text-white hover:bg-white/20",children:e.jsx(h,{className:"w-4 h-4"})})]})]}),!E&&e.jsxs("div",{className:"flex items-center gap-2 text-sm opacity-90",children:[e.jsxs(u,{variant:"secondary",className:"text-xs bg-white/20 text-white border-white/30",children:[e.jsx(p,{className:"w-3 h-3 mr-1"}),"ready"===R?"GPT-4 Ready":"loading"===R?"Loading...":"Error"]}),e.jsxs(u,{variant:"secondary",className:"text-xs bg-white/20 text-white border-white/30",children:[e.jsx(g,{className:"w-3 h-3 mr-1"}),"Token Analysis"]}),e.jsxs(u,{variant:"secondary",className:"text-xs bg-white/20 text-white border-white/30",children:[e.jsx(j,{className:"w-3 h-3 mr-1"}),"Real-time"]})]})]}),!E&&e.jsxs(f,{className:"p-0 flex flex-col h-[calc(100%-100px)]",children:[e.jsx(k,{ref:$,className:"flex-1 p-4",children:e.jsxs("div",{className:"space-y-4",children:[I.map(s=>e.jsxs("div",{className:"space-y-2",children:[e.jsxs("div",{className:r("flex gap-3","user"===s.sender?"justify-end":"justify-start"),children:["bot"===s.sender&&e.jsx("div",{className:"w-8 h-8 rounded-full bg-gradient-to-br from-purple-500 to-pink-500 flex items-center justify-center flex-shrink-0",children:e.jsx(l,{className:"w-4 h-4 text-white"})}),e.jsxs("div",{className:r("max-w-[85%] rounded-lg px-3 py-2 text-sm","user"===s.sender?"bg-gradient-to-r from-purple-600 to-pink-600 text-white":"bg-muted"),children:[e.jsx("div",{className:"whitespace-pre-wrap",children:s.content}),e.jsxs("div",{className:r("text-xs mt-1 opacity-70 flex items-center gap-2","user"===s.sender?"text-white/70":"text-muted-foreground"),children:[e.jsxs("span",{children:[s.tokenCount," tokens"]}),L&&s.tokens.length>0&&e.jsxs("span",{className:"font-mono",children:["[",s.tokens.slice(0,3).join(", "),s.tokens.length>3?"...":"","]"]})]})]}),"user"===s.sender&&e.jsx("div",{className:"w-8 h-8 rounded-full bg-gradient-to-br from-blue-500 to-cyan-500 flex items-center justify-center flex-shrink-0",children:e.jsx(N,{className:"w-4 h-4 text-white"})})]}),L&&s.decodedTokens&&s.decodedTokens.length>0&&e.jsxs("div",{className:r("text-xs p-2 rounded border bg-muted/50 font-mono","user"===s.sender?"ml-12":"mr-12"),children:[e.jsxs("div",{className:"flex items-center gap-1 mb-1 text-muted-foreground",children:[e.jsx(w,{className:"w-3 h-3"}),"Token breakdown:"]}),e.jsxs("div",{className:"flex flex-wrap gap-1",children:[s.decodedTokens.slice(0,15).map((s,t)=>e.jsx("span",{className:"bg-background px-1 py-0.5 rounded border text-xs",children:s.replace(/\s/g,"·")},t)),s.decodedTokens.length>15&&e.jsxs("span",{className:"text-muted-foreground",children:["+",s.decodedTokens.length-15," more"]})]})]})]},s.id)),S&&e.jsxs("div",{className:"flex gap-3 justify-start",children:[e.jsx("div",{className:"w-8 h-8 rounded-full bg-gradient-to-br from-purple-500 to-pink-500 flex items-center justify-center flex-shrink-0",children:e.jsx(l,{className:"w-4 h-4 text-white"})}),e.jsx("div",{className:"bg-muted rounded-lg px-3 py-2 text-sm",children:e.jsxs("div",{className:"flex items-center gap-1",children:[e.jsx("div",{className:"w-2 h-2 bg-gray-400 rounded-full animate-bounce",style:{animationDelay:"0ms"}}),e.jsx("div",{className:"w-2 h-2 bg-gray-400 rounded-full animate-bounce",style:{animationDelay:"150ms"}}),e.jsx("div",{className:"w-2 h-2 bg-gray-400 rounded-full animate-bounce",style:{animationDelay:"300ms"}})]})})]})]})}),e.jsxs("div",{className:"p-4 border-t space-y-2",children:[e.jsxs("div",{className:"flex gap-2",children:[e.jsx(b,{ref:B,value:P,onChange:e=>D(e.target.value),onKeyDown:e=>{"Enter"!==e.key||e.shiftKey||(e.preventDefault(),q())},placeholder:"Ask about tokenization, projects, or ML demos...",className:"flex-1 min-h-[40px] max-h-[100px] resize-none",disabled:S}),e.jsx(t,{onClick:q,disabled:!(null==P?void 0:P.trim())||S,className:"bg-gradient-to-r from-purple-600 to-pink-600 hover:from-purple-700 hover:to-pink-700 text-white self-end",children:e.jsx(y,{className:"w-4 h-4"})})]}),"ready"===R&&(null==P?void 0:P.trim())&&e.jsxs("div",{className:"text-xs text-muted-foreground flex items-center gap-2",children:[e.jsx(g,{className:"w-3 h-3"}),e.jsxs("span",{children:[K.tokenCount," tokens"]}),L&&K.tokens.length>0&&e.jsxs("span",{className:"font-mono",children:["[",K.tokens.slice(0,5).join(", "),K.tokens.length>5?"...":"","]"]})]})]})]})]}):e.jsx(t,{onClick:z,className:"fixed bottom-6 right-6 w-14 h-14 rounded-full bg-gradient-to-r from-purple-600 to-pink-600 hover:from-purple-700 hover:to-pink-700 text-white shadow-lg hover:shadow-xl transition-all duration-200 z-50",size:"icon",children:e.jsx(n,{className:"w-6 h-6"})})},E=()=>{const[r,l]=s.useState(!1),[c,x]=s.useState(!1),[m,h]=s.useState("basic");return e.jsxs("div",{className:"min-h-screen bg-background",children:[e.jsx(T,{}),e.jsxs("div",{className:"pt-16",children:[e.jsx("section",{className:"py-20 px-4",children:e.jsxs("div",{className:"container mx-auto max-w-4xl text-center",children:[e.jsxs("div",{className:"flex items-center justify-center gap-3 mb-6",children:[e.jsx("div",{className:"p-3 bg-gradient-to-br from-purple-500/20 to-pink-500/20 rounded-xl",children:e.jsx(g,{className:"w-8 h-8 text-purple-600"})}),e.jsx("h1",{className:"text-4xl md:text-5xl font-bold bg-gradient-to-r from-purple-600 to-pink-600 bg-clip-text text-transparent",children:"Tokenized AI Chat"})]}),e.jsx("p",{className:"text-xl text-muted-foreground mb-8 max-w-2xl mx-auto",children:"Experience real-time text tokenization with GPT-4's tokenizer. See exactly how your messages get encoded into tokens and decoded back into text - the foundation of modern AI language models."}),e.jsxs("div",{className:"flex flex-wrap justify-center gap-2 mb-8",children:[e.jsxs(u,{variant:"secondary",className:"flex items-center gap-1",children:[e.jsx(p,{className:"w-3 h-3"}),"GPT-4 Tokenizer"]}),e.jsxs(u,{variant:"secondary",className:"flex items-center gap-1",children:[e.jsx(g,{className:"w-3 h-3"}),"Token Analysis"]}),e.jsxs(u,{variant:"secondary",className:"flex items-center gap-1",children:[e.jsx(j,{className:"w-3 h-3"}),"Real-time Processing"]}),e.jsxs(u,{variant:"secondary",className:"flex items-center gap-1",children:[e.jsx(d,{className:"w-3 h-3"}),"Encode/Decode Demo"]})]}),e.jsxs(t,{onClick:()=>l(!0),size:"lg",className:"bg-gradient-to-r from-purple-600 to-pink-600 hover:from-purple-700 hover:to-pink-700 text-white px-8 py-3 rounded-xl",children:[e.jsx(n,{className:"w-5 h-5 mr-2"}),"Start Tokenized Chat"]})]})}),e.jsx("section",{className:"py-16 px-4 bg-muted/30",children:e.jsxs("div",{className:"container mx-auto max-w-6xl",children:[e.jsx("h2",{className:"text-3xl font-bold text-center mb-12",children:"How Tokenization Works"}),e.jsxs("div",{className:"grid grid-cols-1 md:grid-cols-3 gap-6 mb-12",children:[e.jsxs(a,{className:"border-blue-200 dark:border-blue-800",children:[e.jsxs(i,{children:[e.jsxs(o,{className:"flex items-center gap-2",children:[e.jsx(w,{className:"w-5 h-5 text-blue-600"}),"1. Text Input"]}),e.jsx(z,{children:"Your message gets processed character by character"})]}),e.jsxs(f,{children:[e.jsx("div",{className:"bg-blue-400 dark:bg-blue-950/20 p-3 rounded-lg font-mono text-sm",children:'"Hello world!"'}),e.jsx("p",{className:"text-sm text-muted-foreground mt-2",children:"Raw text input ready for tokenization"})]})]}),e.jsxs(a,{className:"border-purple-200 dark:border-purple-800",children:[e.jsxs(i,{children:[e.jsxs(o,{className:"flex items-center gap-2",children:[e.jsx(g,{className:"w-5 h-5 text-purple-600"}),"2. Token Encoding"]}),e.jsx(z,{children:"GPT-4 tokenizer converts text to numerical tokens"})]}),e.jsxs(f,{children:[e.jsx("div",{className:"bg-purple-400 dark:bg-purple-950/20 p-3 rounded-lg font-mono text-sm",children:"[9906, 1917, 0]"}),e.jsx("p",{className:"text-sm text-muted-foreground mt-2",children:"Numerical representation for AI processing"})]})]}),e.jsxs(a,{className:"border-green-200 dark:border-green-800",children:[e.jsxs(i,{children:[e.jsxs(o,{className:"flex items-center gap-2",children:[e.jsx(d,{className:"w-5 h-5 text-green-600"}),"3. Token Decoding"]}),e.jsx(z,{children:"Individual tokens can be decoded back to text"})]}),e.jsxs(f,{children:[e.jsx("div",{className:"bg-green-500 dark:bg-green-950/20 p-3 rounded-lg font-mono text-sm",children:'["Hello", " world", "!"]'}),e.jsx("p",{className:"text-sm text-muted-foreground mt-2",children:"Token-by-token breakdown visualization"})]})]})]}),e.jsxs(I,{className:"max-w-3xl mx-auto",children:[e.jsx(C,{className:"h-4 w-4"}),e.jsx(P,{children:"This demo uses the same GPT-4 tokenizer that powers ChatGPT and other advanced language models. You'll see exactly how your text gets processed in real-time, including token counts and individual token breakdowns."})]})]})}),e.jsx("section",{className:"py-16 px-4",children:e.jsxs("div",{className:"container mx-auto max-w-6xl",children:[e.jsx("h2",{className:"text-3xl font-bold text-center mb-12",children:"Advanced Features"}),e.jsxs("div",{className:"grid grid-cols-1 md:grid-cols-2 lg:grid-cols-3 gap-6",children:[e.jsxs(a,{className:"border-purple-200 dark:border-purple-800",children:[e.jsxs(i,{children:[e.jsxs(o,{className:"flex items-center gap-2",children:[e.jsx(p,{className:"w-5 h-5 text-purple-600"}),"Real-time Tokenization"]}),e.jsx(z,{children:"See tokens update as you type your message"})]}),e.jsx(f,{children:e.jsxs("ul",{className:"text-sm space-y-2 text-muted-foreground",children:[e.jsx("li",{children:"• Live token counting"}),e.jsx("li",{children:"• Instant encoding preview"}),e.jsx("li",{children:"• Character-by-character analysis"})]})})]}),e.jsxs(a,{className:"border-blue-200 dark:border-blue-800",children:[e.jsxs(i,{children:[e.jsxs(o,{className:"flex items-center gap-2",children:[e.jsx(g,{className:"w-5 h-5 text-blue-600"}),"Token Breakdown"]}),e.jsx(z,{children:"Detailed view of how text gets segmented"})]}),e.jsx(f,{children:e.jsxs("ul",{className:"text-sm space-y-2 text-muted-foreground",children:[e.jsx("li",{children:"• Individual token display"}),e.jsx("li",{children:"• Token ID numbers"}),e.jsx("li",{children:"• Decoded token strings"})]})})]}),e.jsxs(a,{className:"border-green-200 dark:border-green-800",children:[e.jsxs(i,{children:[e.jsxs(o,{className:"flex items-center gap-2",children:[e.jsx(D,{className:"w-5 h-5 text-green-600"}),"Interactive Learning"]}),e.jsx(z,{children:"Learn about tokenization through conversation"})]}),e.jsx(f,{children:e.jsxs("ul",{className:"text-sm space-y-2 text-muted-foreground",children:[e.jsx("li",{children:"• Ask about tokenization"}),e.jsx("li",{children:"• Portfolio knowledge base"}),e.jsx("li",{children:"• Technical explanations"})]})})]}),e.jsxs(a,{className:"border-orange-200 dark:border-orange-800",children:[e.jsxs(i,{children:[e.jsxs(o,{className:"flex items-center gap-2",children:[e.jsx(j,{className:"w-5 h-5 text-orange-600"}),"Performance Optimized"]}),e.jsx(z,{children:"Efficient client-side processing"})]}),e.jsx(f,{children:e.jsxs("ul",{className:"text-sm space-y-2 text-muted-foreground",children:[e.jsx("li",{children:"• WebAssembly acceleration"}),e.jsx("li",{children:"• No server round-trips"}),e.jsx("li",{children:"• Instant responses"})]})})]}),e.jsxs(a,{className:"border-pink-200 dark:border-pink-800",children:[e.jsxs(i,{children:[e.jsxs(o,{className:"flex items-center gap-2",children:[e.jsx(d,{className:"w-5 h-5 text-pink-600"}),"Developer Insights"]}),e.jsx(z,{children:"Perfect for understanding AI internals"})]}),e.jsx(f,{children:e.jsxs("ul",{className:"text-sm space-y-2 text-muted-foreground",children:[e.jsx("li",{children:"• Token visualization"}),e.jsx("li",{children:"• Encoding algorithms"}),e.jsx("li",{children:"• AI model foundations"})]})})]}),e.jsxs(a,{className:"border-cyan-200 dark:border-cyan-800",children:[e.jsxs(i,{children:[e.jsxs(o,{className:"flex items-center gap-2",children:[e.jsx(n,{className:"w-5 h-5 text-cyan-600"}),"Contextual Responses"]}),e.jsx(z,{children:"AI responses aware of tokenization process"})]}),e.jsx(f,{children:e.jsxs("ul",{className:"text-sm space-y-2 text-muted-foreground",children:[e.jsx("li",{children:"• Token-aware conversations"}),e.jsx("li",{children:"• Educational responses"}),e.jsx("li",{children:"• Technical depth control"})]})})]})]})]})}),e.jsx("section",{className:"py-16 px-4 bg-muted/30",children:e.jsxs("div",{className:"container mx-auto max-w-4xl",children:[e.jsxs("div",{className:"text-center mb-12",children:[e.jsx("h2",{className:"text-3xl font-bold mb-4",children:"Try the Tokenized Chat"}),e.jsx("p",{className:"text-muted-foreground",children:"Experience the power of real-time tokenization and see how AI processes language"})]}),e.jsxs("div",{className:"grid grid-cols-1 md:grid-cols-2 gap-6",children:[e.jsxs("div",{className:"bg-gradient-to-br from-purple-50 to-pink-50 dark:from-purple-950/20 dark:to-pink-950/20 rounded-2xl p-6",children:[e.jsxs("div",{className:"text-center mb-4",children:[e.jsx("div",{className:"inline-flex p-3 bg-white dark:bg-gray-800 rounded-full shadow-lg mb-3",children:e.jsx(g,{className:"w-6 h-6 text-purple-600"})}),e.jsx("h3",{className:"text-lg font-semibold mb-2",children:"Basic Tokenization"}),e.jsx("p",{className:"text-sm text-muted-foreground",children:"See how text gets encoded into tokens with curated educational responses"})]}),e.jsxs("div",{className:"space-y-2 text-xs text-muted-foreground mb-4",children:[e.jsx("div",{className:"flex items-center gap-2",children:e.jsx(u,{variant:"outline",className:"text-xs text-gray-500",children:"✅ GPT-4 Tokenizer"})}),e.jsx("div",{className:"flex items-center gap-2",children:e.jsx(u,{variant:"outline",className:"text-xs text-gray-500",children:"✅ Real-time Token Counting"})}),e.jsx("div",{className:"flex items-center gap-2",children:e.jsx(u,{variant:"outline",className:"text-xs text-gray-500",children:"📝 Curated Responses"})})]}),e.jsxs(t,{onClick:()=>{h("basic"),l(!0)},className:"w-full bg-gradient-to-r from-purple-600 to-pink-600 hover:from-purple-700 hover:to-pink-700 text-white",children:[e.jsx(n,{className:"w-4 h-4 mr-2"}),"Try Basic Mode"]})]}),e.jsxs("div",{className:"bg-gradient-to-br from-blue-50 to-purple-50 dark:from-blue-950/20 dark:to-purple-950/20 rounded-2xl p-6",children:[e.jsxs("div",{className:"text-center mb-4",children:[e.jsx("div",{className:"inline-flex p-3 bg-white dark:bg-gray-800 rounded-full shadow-lg mb-3",children:e.jsx(p,{className:"w-6 h-6 text-blue-600"})}),e.jsx("h3",{className:"text-lg font-semibold mb-2",children:"AI Generation + Tokens"}),e.jsx("p",{className:"text-sm text-muted-foreground",children:"Full NLP pipeline with actual AI text generation and tokenization"})]}),e.jsxs("div",{className:"space-y-2 text-xs text-muted-foreground mb-4",children:[e.jsx("div",{className:"flex items-center gap-2",children:e.jsx(u,{variant:"outline",className:"text-xs text-gray-500",children:"✅ GPT-4 Tokenizer"})}),e.jsx("div",{className:"flex items-center gap-2",children:e.jsx(u,{variant:"outline",className:"text-xs text-gray-500",children:"🤖 DistilGPT-2 Generation"})}),e.jsx("div",{className:"flex items-center gap-2",children:e.jsx(u,{variant:"outline",className:"text-xs text-gray-500",children:"⚡ Full NLP Pipeline"})})]}),e.jsxs(t,{onClick:()=>{h("advanced"),x(!0)},className:"w-full bg-gradient-to-r from-blue-600 to-purple-600 hover:from-blue-700 hover:to-purple-700 text-white",children:[e.jsx(p,{className:"w-4 h-4 mr-2"}),"Try AI Generation"]})]})]}),e.jsx("div",{className:"mt-8 text-center",children:e.jsxs("div",{className:"space-y-3 text-sm text-muted-foreground mb-6",children:[e.jsx("p",{children:"Try asking either mode:"}),e.jsxs("div",{className:"flex flex-wrap justify-center gap-2",children:[e.jsx(u,{variant:"outline",children:'"How does tokenization work?"'}),e.jsx(u,{variant:"outline",children:'"Generate a creative response"'}),e.jsx(u,{variant:"outline",children:'"Explain the difference between modes"'}),e.jsx(u,{variant:"outline",children:'"What are Carlos\'s ML projects?"'})]})]})})]})}),e.jsx("section",{className:"py-16 px-4",children:e.jsxs("div",{className:"container mx-auto max-w-4xl",children:[e.jsx("h2",{className:"text-3xl font-bold text-center mb-12",children:"Technical Implementation"}),e.jsxs("div",{className:"grid grid-cols-1 md:grid-cols-2 gap-8",children:[e.jsxs(a,{children:[e.jsxs(i,{children:[e.jsx(o,{children:"Tokenizer Details"}),e.jsx(z,{children:"GPT-4 tokenizer specifications and capabilities"})]}),e.jsxs(f,{className:"space-y-3",children:[e.jsxs("div",{className:"flex justify-between",children:[e.jsx("span",{className:"text-sm text-muted-foreground",children:"Model:"}),e.jsx("span",{className:"text-sm font-mono",children:"Xenova/gpt-4"})]}),e.jsxs("div",{className:"flex justify-between",children:[e.jsx("span",{className:"text-sm text-muted-foreground",children:"Vocabulary Size:"}),e.jsx("span",{className:"text-sm font-mono",children:"~100k tokens"})]}),e.jsxs("div",{className:"flex justify-between",children:[e.jsx("span",{className:"text-sm text-muted-foreground",children:"Encoding:"}),e.jsx("span",{className:"text-sm font-mono",children:"BPE (Byte-Pair)"})]}),e.jsxs("div",{className:"flex justify-between",children:[e.jsx("span",{className:"text-sm text-muted-foreground",children:"Languages:"}),e.jsx("span",{className:"text-sm",children:"Multilingual"})]})]})]}),e.jsxs(a,{children:[e.jsxs(i,{children:[e.jsx(o,{children:"Performance Metrics"}),e.jsx(z,{children:"Real-time processing capabilities"})]}),e.jsxs(f,{className:"space-y-3",children:[e.jsxs("div",{className:"flex justify-between",children:[e.jsx("span",{className:"text-sm text-muted-foreground",children:"Tokenization Speed:"}),e.jsx("span",{className:"text-sm",children:"~1ms per message"})]}),e.jsxs("div",{className:"flex justify-between",children:[e.jsx("span",{className:"text-sm text-muted-foreground",children:"Memory Usage:"}),e.jsx("span",{className:"text-sm",children:"~50MB loaded"})]}),e.jsxs("div",{className:"flex justify-between",children:[e.jsx("span",{className:"text-sm text-muted-foreground",children:"Processing:"}),e.jsx("span",{className:"text-sm",children:"Client-side only"})]}),e.jsxs("div",{className:"flex justify-between",children:[e.jsx("span",{className:"text-sm text-muted-foreground",children:"Framework:"}),e.jsx("span",{className:"text-sm font-mono",children:"Transformers.js"})]})]})]})]})]})})]}),"basic"===m&&e.jsx(G,{isOpen:r,onToggle:()=>l(!r)}),"advanced"===m&&e.jsx(S,{isOpen:c,onToggle:()=>x(!c)})]})};export{E as default};
