import{j as e}from"./chunk-BXEcVBbX.js";import{r as s}from"./chunk-DRBa9aRh.js";import{c as t,b as n,v as a,d as r,m as o,e as i,f as l,t as c,M as d,x as m,X as x,B as h,Z as u,h as p,y as g,U as j,T as f,z as k,H as b,g as N,r as w,s as y,w as v}from"./index-BVnNQW-c.js";import{B as T}from"./chunk-l0EBB2fH.js";import{_ as z}from"./chunk-C_tfXL3w.js";import{a as I,I as C}from"./chunk-BnbvnZUN.js";import{L as P}from"./chunk-qa2oD1zY.js";import{C as S}from"./chunk-BrQjJk2L.js";import{A as D}from"./chunk-Dlt4JwqC.js";import{S as A}from"./chunk-CacNU5re.js";import"./transformers.web.js-BNI60vAQ.js";
/**
 * @license lucide-react v0.462.0 - ISC
 *
 * This source code is licensed under the ISC license.
 * See the LICENSE file in the root directory of this source tree.
 */const G=t("Hash",[["line",{x1:"4",x2:"20",y1:"9",y2:"9",key:"4lhtct"}],["line",{x1:"4",x2:"20",y1:"15",y2:"15",key:"vyu0kd"}],["line",{x1:"10",x2:"8",y1:"3",y2:"21",key:"1ggp8o"}],["line",{x1:"16",x2:"14",y1:"3",y2:"21",key:"weycgp"}]]),E=({isOpen:t,onToggle:b})=>{const[N,w]=s.useState([]),[y,v]=s.useState(""),[C,A]=s.useState(!1),[E,M]=s.useState(!1),[R,_]=s.useState("loading"),[L,H]=s.useState(!1),$=s.useRef(null),B=s.useRef(null),F=s.useRef(null),Y=s.useRef(!1);s.useEffect(()=>(Y.current=!0,()=>{Y.current=!1}),[]),s.useEffect(()=>{if(!t||!Y.current||"loading"!==R)return;const e=setTimeout(async()=>{try{const{AutoTokenizer:e}=await z(async()=>{const{AutoTokenizer:e}=await import("./transformers.web.js-BNI60vAQ.js");return{AutoTokenizer:e}},[]);if(!Y.current)return;const s=await e.from_pretrained("Xenova/gpt-4");if(!Y.current)return;const t="Hello! I can encode and decode tokens.";s.encode(t).map(e=>s.decode([e]));F.current=s,_("ready");const n="Hi! I'm your AI assistant with GPT-4 tokenization. I can show you exactly how text gets encoded into tokens and decoded back. Try sending a message to see the tokenization process in action!",a=s.encode(n),r=a.map(e=>s.decode([e]));w([{id:Date.now().toString(),content:n,sender:"bot",timestamp:new Date,tokens:a,tokenCount:a.length,decodedTokens:r}])}catch(e){Y.current&&(_("error"),w([{id:Date.now().toString(),content:"I encountered an error loading the tokenizer, but I can still chat with you! The tokenization features won't be available in this session.",sender:"bot",timestamp:new Date,tokens:[],tokenCount:0}]))}},500);return()=>clearTimeout(e)},[t,R]),s.useEffect(()=>{if($.current){const e=$.current.querySelector("[data-radix-scroll-area-viewport]");e&&(e.scrollTop=e.scrollHeight)}},[N]),s.useEffect(()=>{t&&!E&&B.current&&setTimeout(()=>{var e;return null==(e=B.current)?void 0:e.focus()},100)},[t,E]);const O=e=>{if("ready"!==R||!F.current||!e)return{tokens:[],decodedTokens:[],tokenCount:0};try{const s=F.current.encode(e),t=s.map(e=>F.current.decode([e]));return{tokens:s,decodedTokens:t,tokenCount:s.length}}catch(s){return{tokens:[],decodedTokens:[],tokenCount:0}}},W=(e,s)=>{const t=e.toLowerCase();if(t.includes("token")||t.includes("encode")||t.includes("decode")){return`${s.length>0?`Your message was encoded into ${s.length} tokens: [${s.slice(0,10).join(", ")}${s.length>10?"...":""}]. `:""}Tokenization is fascinating! Here's how it works:\n\n🔤 **Encoding**: Text → Numbers (tokens)\n🔢 **Processing**: AI models work with these numbers\n📝 **Decoding**: Numbers → Text output\n\nEach token represents a piece of text - could be a word, part of a word, or punctuation. GPT-4 uses a sophisticated tokenizer that handles multiple languages and special characters efficiently!`}if(t.includes("how")&&(t.includes("work")||t.includes("process")))return`Great question! Here's my processing pipeline:\n\n1️⃣ **Input Tokenization**: Your text gets encoded into ${s.length} tokens\n2️⃣ **Language Model**: I use DistilGPT-2 for text generation\n3️⃣ **Response Generation**: AI generates contextual responses\n4️⃣ **Output Tokenization**: My response gets tokenized too\n\nThis demonstrates the full NLP pipeline: tokenization → language model → generation → detokenization!`;if(t.includes("project")||t.includes("portfolio"))return`I'd love to tell you about Carlos's projects! Your ${s.length}-token question shows you're interested in his work.\n\n🚀 **Key Projects**:\n• SIDS Prediction Model (Healthcare AI)\n• Real-time Image Classification\n• Sentiment Analysis with BERT\n• This very chat system with GPT-4 tokenization + DistilGPT-2!\n\nEach project demonstrates different aspects of ML engineering - from data preprocessing to model deployment. Which one interests you most?`;if(t.includes("sids")||t.includes("capstone"))return"The SIDS Prediction Model is Carlos's flagship project! It processes physiological data through multiple tokenization and encoding stages:\n\n🏥 **Medical Data Pipeline**:\n• Sensor data → Feature tokens\n• Time series → Sequence encoding\n• Risk factors → Classification tokens\n• Predictions → Probability scores\n\nJust like how I tokenize text, the SIDS model tokenizes medical data to identify patterns that could save lives. It's a powerful example of AI for social good!";if(t.includes("technology")||t.includes("tech"))return`This portfolio showcases cutting-edge tech! Your message used ${s.length} tokens to ask about it.\n\n⚡ **Frontend**: React 18 + TypeScript\n🧠 **AI**: Hugging Face Transformers.js\n🔧 **Tokenization**: GPT-4 tokenizer\n🤖 **Generation**: DistilGPT-2 language model\n🎨 **UI**: Tailwind CSS + Shadcn/ui\n☁️ **Backend**: Supabase + Edge Functions\n\nEverything runs client-side for instant ML inference - no server round-trips needed!`;const n=[`[${s.length} tokens processed] I'm an AI assistant showcasing Carlos's ML portfolio. I use real tokenization and text generation models. What would you like to know about his projects, skills, or this chat system?`,`[Generated from ${s.length} input tokens] Thanks for your message! I demonstrate both tokenization and language generation. Carlos built this to show how modern NLP works. What aspect interests you most?`,`[Tokenized: ${s.length} tokens] Your message went through the full NLP pipeline - tokenization, language model processing, and generation. This showcases the same techniques Carlos uses in his ML projects. How can I help you learn more?`];return n[Math.floor(Math.random()*n.length)]},q=async()=>{const e=(null==y?void 0:y.trim())||"";if(!e)return;const{tokens:s,decodedTokens:t,tokenCount:n}=O(e),a={id:Date.now().toString(),content:e,sender:"user",timestamp:new Date,tokens:s,tokenCount:n,decodedTokens:t};w(e=>[...e,a]),v(""),A(!0);try{const e=await(async(e,s)=>{if("ready"!==R||!F.current)return"I'm still loading my language capabilities. Please wait a moment and try again!";try{const{pipeline:t}=await z(async()=>{const{pipeline:e}=await import("./transformers.web.js-BNI60vAQ.js");return{pipeline:e}},[]),n=await t("text-generation","Xenova/distilgpt2",{max_new_tokens:100,do_sample:!0,top_k:50,top_p:.95,temperature:.7}),a=`You are an AI assistant for Carlos Gonzalez Rivera's ML portfolio. The user said: "${e}" (${s.length} tokens). Respond helpfully about his ML projects, skills, or tokenization. Keep it concise and informative.\n\nResponse:`;let r=(await n(a,{max_new_tokens:80,do_sample:!0,top_k:50,top_p:.95,temperature:.7,pad_token_id:50256}))[0].generated_text;return r=r.replace(a,"").trim(),r.length<20||!r.includes(" ")?W(e,s):`[Generated using ${s.length} input tokens] `+r}catch(t){return W(e,s)}})(a.content,a.tokens),{tokens:s,decodedTokens:t,tokenCount:n}=O(e),r={id:(Date.now()+1).toString(),content:e,sender:"bot",timestamp:new Date,tokens:s,tokenCount:n,decodedTokens:t};w(e=>[...e,r]),(async(e,s)=>{try{const t={maxAdditionalTokens:30,timeoutMs:5e3,minCompletionLength:5,contentType:"conversational",languageCode:"en"},n=[{role:"user",content:s},{role:"assistant",content:e.content}],a=await I(e.content,n,"simple-fallback",t);a.wasCompleted&&a.completedText!==e.content&&w(s=>s.map(s=>{if(s.id===e.id){const{tokens:e,decodedTokens:t,tokenCount:n}=O(a.completedText);return{...s,content:a.completedText,tokens:e,decodedTokens:t,tokenCount:n,completionInfo:{wasCompleted:!0,additionalTokensUsed:a.additionalTokensUsed,completionReason:a.completionReason,processingTimeMs:a.processingTimeMs}}}return s}))}catch(t){}})(r,a.content)}catch(r){const e="I apologize, but I encountered an error processing your message. Please try again!",{tokens:s,decodedTokens:t,tokenCount:n}=O(e),a={id:(Date.now()+1).toString(),content:e,sender:"bot",timestamp:new Date,tokens:s,tokenCount:n,decodedTokens:t};w(e=>[...e,a])}finally{A(!1)}},U=O(y);return t?e.jsxs(r,{className:o("fixed bottom-4 right-4 mobile:bottom-0 mobile:right-0 mobile:left-0 mobile:top-0 w-[420px] mobile:w-full mobile:h-full shadow-2xl border-purple-200 dark:border-purple-800 z-50 transition-all duration-300 mobile:rounded-none",E?"h-16 mobile:h-16":"h-[600px] mobile:h-full"),children:[e.jsxs(i,{className:"pb-3 bg-gradient-to-r from-purple-600 to-pink-600 text-white rounded-t-lg mobile:rounded-none mobile:pb-2",children:[e.jsxs("div",{className:"flex items-center justify-between",children:[e.jsxs(l,{className:"flex items-center gap-2 text-lg mobile:text-base mobile:gap-1",children:[e.jsx(c,{className:"w-5 h-5"}),"Tokenized AI Chat","loading"===R&&e.jsx(P,{className:"w-4 h-4 animate-spin"})]}),e.jsxs("div",{className:"flex items-center gap-1 mobile:gap-0.5",children:[e.jsx(n,{variant:"ghost",size:"icon",onClick:()=>H(!L),className:"w-8 h-8 mobile:w-9 mobile:h-9 text-white hover:bg-white/20 touch:active:scale-95",title:"Toggle token details",children:e.jsx(S,{className:"w-4 h-4"})}),e.jsx(n,{variant:"ghost",size:"icon",onClick:()=>M(!E),className:"w-8 h-8 mobile:w-9 mobile:h-9 text-white hover:bg-white/20 touch:active:scale-95 mobile:hidden",children:E?e.jsx(d,{className:"w-4 h-4"}):e.jsx(m,{className:"w-4 h-4"})}),e.jsx(n,{variant:"ghost",size:"icon",onClick:b,className:"w-8 h-8 mobile:w-9 mobile:h-9 text-white hover:bg-white/20 touch:active:scale-95",children:e.jsx(x,{className:"w-4 h-4"})})]})]}),!E&&e.jsxs("div",{className:"flex items-center gap-2 mobile:gap-1 text-sm mobile:text-xs opacity-90",children:[e.jsxs(T,{variant:"secondary",className:"text-xs bg-white/20 text-white border-white/30",children:[e.jsx(h,{className:"w-3 h-3 mr-1"}),"ready"===R?"GPT-4 Ready":"loading"===R?"Loading...":"Error"]}),e.jsxs(T,{variant:"secondary",className:"text-xs bg-white/20 text-white border-white/30",children:[e.jsx(G,{className:"w-3 h-3 mr-1"}),"Token Analysis"]}),e.jsxs(T,{variant:"secondary",className:"text-xs bg-white/20 text-white border-white/30",children:[e.jsx(u,{className:"w-3 h-3 mr-1"}),"Real-time"]})]})]}),!E&&e.jsxs(p,{className:"p-0 flex flex-col h-[calc(100%-100px)] mobile:h-[calc(100vh-100px)]",children:[e.jsx(g,{ref:$,className:"flex-1 p-4 mobile:p-3",children:e.jsxs("div",{className:"space-y-4",children:[N.map(s=>e.jsxs("div",{className:"space-y-2",children:[e.jsxs("div",{className:o("flex gap-3","user"===s.sender?"justify-end":"justify-start"),children:["bot"===s.sender&&e.jsx("div",{className:"w-8 h-8 rounded-full bg-gradient-to-br from-purple-500 to-pink-500 flex items-center justify-center flex-shrink-0",children:e.jsx(c,{className:"w-4 h-4 text-white"})}),e.jsxs("div",{className:o("max-w-[85%] rounded-lg px-3 py-2 text-sm","user"===s.sender?"bg-gradient-to-r from-purple-600 to-pink-600 text-white":"bg-muted"),children:[e.jsx("div",{className:"whitespace-pre-wrap",children:s.content}),e.jsxs("div",{className:o("text-xs mt-1 opacity-70 flex items-center gap-2","user"===s.sender?"text-white/70":"text-muted-foreground"),children:[e.jsxs("span",{children:[s.tokenCount," tokens"]}),L&&s.tokens.length>0&&e.jsxs("span",{className:"font-mono",children:["[",s.tokens.slice(0,3).join(", "),s.tokens.length>3?"...":"","]"]})]})]}),"user"===s.sender&&e.jsx("div",{className:"w-8 h-8 rounded-full bg-gradient-to-br from-blue-500 to-cyan-500 flex items-center justify-center flex-shrink-0",children:e.jsx(j,{className:"w-4 h-4 text-white"})})]}),L&&s.decodedTokens&&s.decodedTokens.length>0&&e.jsxs("div",{className:o("text-xs p-2 rounded border bg-muted/50 font-mono","user"===s.sender?"ml-12":"mr-12"),children:[e.jsxs("div",{className:"flex items-center gap-1 mb-1 text-muted-foreground",children:[e.jsx(D,{className:"w-3 h-3"}),"Token breakdown:"]}),e.jsxs("div",{className:"flex flex-wrap gap-1",children:[s.decodedTokens.slice(0,15).map((s,t)=>e.jsx("span",{className:"bg-background px-1 py-0.5 rounded border text-xs",children:s.replace(/\s/g,"·")},t)),s.decodedTokens.length>15&&e.jsxs("span",{className:"text-muted-foreground",children:["+",s.decodedTokens.length-15," more"]})]})]})]},s.id)),C&&e.jsxs("div",{className:"flex gap-3 justify-start",children:[e.jsx("div",{className:"w-8 h-8 rounded-full bg-gradient-to-br from-purple-500 to-pink-500 flex items-center justify-center flex-shrink-0",children:e.jsx(c,{className:"w-4 h-4 text-white"})}),e.jsx("div",{className:"bg-muted rounded-lg px-3 py-2 text-sm",children:e.jsxs("div",{className:"flex items-center gap-1",children:[e.jsx("div",{className:"w-2 h-2 bg-gray-400 rounded-full animate-bounce",style:{animationDelay:"0ms"}}),e.jsx("div",{className:"w-2 h-2 bg-gray-400 rounded-full animate-bounce",style:{animationDelay:"150ms"}}),e.jsx("div",{className:"w-2 h-2 bg-gray-400 rounded-full animate-bounce",style:{animationDelay:"300ms"}})]})})]})]})}),e.jsxs("div",{className:"p-4 border-t space-y-2",children:[e.jsxs("div",{className:"flex gap-2",children:[e.jsx(f,{ref:B,value:y,onChange:e=>v(e.target.value),onKeyDown:e=>{"Enter"!==e.key||e.shiftKey||(e.preventDefault(),q())},placeholder:"Ask about tokenization, projects, or ML demos...",className:"flex-1 min-h-[40px] max-h-[100px] resize-none",disabled:C}),e.jsx(n,{onClick:q,disabled:!(null==y?void 0:y.trim())||C,className:"bg-gradient-to-r from-purple-600 to-pink-600 hover:from-purple-700 hover:to-pink-700 text-white self-end",children:e.jsx(k,{className:"w-4 h-4"})})]}),"ready"===R&&(null==y?void 0:y.trim())&&e.jsxs("div",{className:"text-xs text-muted-foreground flex items-center gap-2",children:[e.jsx(G,{className:"w-3 h-3"}),e.jsxs("span",{children:[U.tokenCount," tokens"]}),L&&U.tokens.length>0&&e.jsxs("span",{className:"font-mono",children:["[",U.tokens.slice(0,5).join(", "),U.tokens.length>5?"...":"","]"]})]})]})]})]}):e.jsx(n,{onClick:b,className:"fixed bottom-4 right-4 mobile:bottom-3 mobile:right-3 w-14 h-14 mobile:w-12 mobile:h-12 rounded-full bg-gradient-to-r from-purple-600 to-pink-600 hover:from-purple-700 hover:to-pink-700 text-white shadow-lg hover:shadow-xl transition-all duration-200 z-50 touch:active:scale-95",size:"icon",children:e.jsx(a,{className:"w-6 h-6 mobile:w-5 mobile:h-5"})})},M=()=>{const[t,o]=s.useState(!1),[c,d]=s.useState(!1),[m,x]=s.useState("basic");return e.jsxs("div",{className:"min-h-screen bg-background",children:[e.jsx(b,{}),e.jsxs("div",{className:"pt-16",children:[e.jsx("section",{className:"py-20 px-4",children:e.jsxs("div",{className:"container mx-auto max-w-4xl text-center",children:[e.jsxs("div",{className:"flex items-center justify-center gap-3 mb-6",children:[e.jsx("div",{className:"p-3 bg-gradient-to-br from-purple-500/20 to-pink-500/20 rounded-xl",children:e.jsx(G,{className:"w-8 h-8 text-purple-600"})}),e.jsx("h1",{className:"text-4xl md:text-5xl font-bold bg-gradient-to-r from-purple-600 to-pink-600 bg-clip-text text-transparent",children:"Tokenized AI Chat"})]}),e.jsx("p",{className:"text-xl text-muted-foreground mb-8 max-w-2xl mx-auto",children:"Experience real-time text tokenization with GPT-4's tokenizer. See exactly how your messages get encoded into tokens and decoded back into text - the foundation of modern AI language models."}),e.jsxs("div",{className:"flex flex-wrap justify-center gap-2 mb-8",children:[e.jsxs(T,{variant:"secondary",className:"flex items-center gap-1",children:[e.jsx(h,{className:"w-3 h-3"}),"GPT-4 Tokenizer"]}),e.jsxs(T,{variant:"secondary",className:"flex items-center gap-1",children:[e.jsx(G,{className:"w-3 h-3"}),"Token Analysis"]}),e.jsxs(T,{variant:"secondary",className:"flex items-center gap-1",children:[e.jsx(u,{className:"w-3 h-3"}),"Real-time Processing"]}),e.jsxs(T,{variant:"secondary",className:"flex items-center gap-1",children:[e.jsx(S,{className:"w-3 h-3"}),"Encode/Decode Demo"]})]}),e.jsxs(n,{onClick:()=>o(!0),size:"lg",className:"bg-gradient-to-r from-purple-600 to-pink-600 hover:from-purple-700 hover:to-pink-700 text-white px-8 py-3 rounded-xl",children:[e.jsx(a,{className:"w-5 h-5 mr-2"}),"Start Tokenized Chat"]})]})}),e.jsx("section",{className:"py-16 px-4 bg-muted/30",children:e.jsxs("div",{className:"container mx-auto max-w-6xl",children:[e.jsx("h2",{className:"text-3xl font-bold text-center mb-12",children:"How Tokenization Works"}),e.jsxs("div",{className:"grid grid-cols-1 md:grid-cols-3 gap-6 mb-12",children:[e.jsxs(r,{className:"border-blue-200 dark:border-blue-800",children:[e.jsxs(i,{children:[e.jsxs(l,{className:"flex items-center gap-2",children:[e.jsx(D,{className:"w-5 h-5 text-blue-600"}),"1. Text Input"]}),e.jsx(N,{children:"Your message gets processed character by character"})]}),e.jsxs(p,{children:[e.jsx("div",{className:"bg-blue-400 dark:bg-blue-950/20 p-3 rounded-lg font-mono text-sm",children:'"Hello world!"'}),e.jsx("p",{className:"text-sm text-muted-foreground mt-2",children:"Raw text input ready for tokenization"})]})]}),e.jsxs(r,{className:"border-purple-200 dark:border-purple-800",children:[e.jsxs(i,{children:[e.jsxs(l,{className:"flex items-center gap-2",children:[e.jsx(G,{className:"w-5 h-5 text-purple-600"}),"2. Token Encoding"]}),e.jsx(N,{children:"GPT-4 tokenizer converts text to numerical tokens"})]}),e.jsxs(p,{children:[e.jsx("div",{className:"bg-purple-400 dark:bg-purple-950/20 p-3 rounded-lg font-mono text-sm",children:"[9906, 1917, 0]"}),e.jsx("p",{className:"text-sm text-muted-foreground mt-2",children:"Numerical representation for AI processing"})]})]}),e.jsxs(r,{className:"border-green-200 dark:border-green-800",children:[e.jsxs(i,{children:[e.jsxs(l,{className:"flex items-center gap-2",children:[e.jsx(S,{className:"w-5 h-5 text-green-600"}),"3. Token Decoding"]}),e.jsx(N,{children:"Individual tokens can be decoded back to text"})]}),e.jsxs(p,{children:[e.jsx("div",{className:"bg-green-500 dark:bg-green-950/20 p-3 rounded-lg font-mono text-sm",children:'["Hello", " world", "!"]'}),e.jsx("p",{className:"text-sm text-muted-foreground mt-2",children:"Token-by-token breakdown visualization"})]})]})]}),e.jsxs(w,{className:"max-w-3xl mx-auto",children:[e.jsx(C,{className:"h-4 w-4"}),e.jsx(y,{children:"This demo uses the same GPT-4 tokenizer that powers ChatGPT and other advanced language models. You'll see exactly how your text gets processed in real-time, including token counts and individual token breakdowns."})]})]})}),e.jsx("section",{className:"py-16 px-4",children:e.jsxs("div",{className:"container mx-auto max-w-6xl",children:[e.jsx("h2",{className:"text-3xl font-bold text-center mb-12",children:"Advanced Features"}),e.jsxs("div",{className:"grid grid-cols-1 md:grid-cols-2 lg:grid-cols-3 gap-6",children:[e.jsxs(r,{className:"border-purple-200 dark:border-purple-800",children:[e.jsxs(i,{children:[e.jsxs(l,{className:"flex items-center gap-2",children:[e.jsx(h,{className:"w-5 h-5 text-purple-600"}),"Real-time Tokenization"]}),e.jsx(N,{children:"See tokens update as you type your message"})]}),e.jsx(p,{children:e.jsxs("ul",{className:"text-sm space-y-2 text-muted-foreground",children:[e.jsx("li",{children:"• Live token counting"}),e.jsx("li",{children:"• Instant encoding preview"}),e.jsx("li",{children:"• Character-by-character analysis"})]})})]}),e.jsxs(r,{className:"border-blue-200 dark:border-blue-800",children:[e.jsxs(i,{children:[e.jsxs(l,{className:"flex items-center gap-2",children:[e.jsx(G,{className:"w-5 h-5 text-blue-600"}),"Token Breakdown"]}),e.jsx(N,{children:"Detailed view of how text gets segmented"})]}),e.jsx(p,{children:e.jsxs("ul",{className:"text-sm space-y-2 text-muted-foreground",children:[e.jsx("li",{children:"• Individual token display"}),e.jsx("li",{children:"• Token ID numbers"}),e.jsx("li",{children:"• Decoded token strings"})]})})]}),e.jsxs(r,{className:"border-green-200 dark:border-green-800",children:[e.jsxs(i,{children:[e.jsxs(l,{className:"flex items-center gap-2",children:[e.jsx(A,{className:"w-5 h-5 text-green-600"}),"Interactive Learning"]}),e.jsx(N,{children:"Learn about tokenization through conversation"})]}),e.jsx(p,{children:e.jsxs("ul",{className:"text-sm space-y-2 text-muted-foreground",children:[e.jsx("li",{children:"• Ask about tokenization"}),e.jsx("li",{children:"• Portfolio knowledge base"}),e.jsx("li",{children:"• Technical explanations"})]})})]}),e.jsxs(r,{className:"border-orange-200 dark:border-orange-800",children:[e.jsxs(i,{children:[e.jsxs(l,{className:"flex items-center gap-2",children:[e.jsx(u,{className:"w-5 h-5 text-orange-600"}),"Performance Optimized"]}),e.jsx(N,{children:"Efficient client-side processing"})]}),e.jsx(p,{children:e.jsxs("ul",{className:"text-sm space-y-2 text-muted-foreground",children:[e.jsx("li",{children:"• WebAssembly acceleration"}),e.jsx("li",{children:"• No server round-trips"}),e.jsx("li",{children:"• Instant responses"})]})})]}),e.jsxs(r,{className:"border-pink-200 dark:border-pink-800",children:[e.jsxs(i,{children:[e.jsxs(l,{className:"flex items-center gap-2",children:[e.jsx(S,{className:"w-5 h-5 text-pink-600"}),"Developer Insights"]}),e.jsx(N,{children:"Perfect for understanding AI internals"})]}),e.jsx(p,{children:e.jsxs("ul",{className:"text-sm space-y-2 text-muted-foreground",children:[e.jsx("li",{children:"• Token visualization"}),e.jsx("li",{children:"• Encoding algorithms"}),e.jsx("li",{children:"• AI model foundations"})]})})]}),e.jsxs(r,{className:"border-cyan-200 dark:border-cyan-800",children:[e.jsxs(i,{children:[e.jsxs(l,{className:"flex items-center gap-2",children:[e.jsx(a,{className:"w-5 h-5 text-cyan-600"}),"Contextual Responses"]}),e.jsx(N,{children:"AI responses aware of tokenization process"})]}),e.jsx(p,{children:e.jsxs("ul",{className:"text-sm space-y-2 text-muted-foreground",children:[e.jsx("li",{children:"• Token-aware conversations"}),e.jsx("li",{children:"• Educational responses"}),e.jsx("li",{children:"• Technical depth control"})]})})]})]})]})}),e.jsx("section",{className:"py-16 px-4 bg-muted/30",children:e.jsxs("div",{className:"container mx-auto max-w-4xl",children:[e.jsxs("div",{className:"text-center mb-12",children:[e.jsx("h2",{className:"text-3xl font-bold mb-4",children:"Try the Tokenized Chat"}),e.jsx("p",{className:"text-muted-foreground",children:"Experience the power of real-time tokenization and see how AI processes language"})]}),e.jsxs("div",{className:"grid grid-cols-1 md:grid-cols-2 gap-6",children:[e.jsxs("div",{className:"bg-gradient-to-br from-purple-50 to-pink-50 dark:from-purple-950/20 dark:to-pink-950/20 rounded-2xl p-6",children:[e.jsxs("div",{className:"text-center mb-4",children:[e.jsx("div",{className:"inline-flex p-3 bg-white dark:bg-gray-800 rounded-full shadow-lg mb-3",children:e.jsx(G,{className:"w-6 h-6 text-purple-600"})}),e.jsx("h3",{className:"text-lg font-semibold mb-2",children:"Basic Tokenization"}),e.jsx("p",{className:"text-sm text-muted-foreground",children:"See how text gets encoded into tokens with curated educational responses"})]}),e.jsxs("div",{className:"space-y-2 text-xs text-muted-foreground mb-4",children:[e.jsx("div",{className:"flex items-center gap-2",children:e.jsx(T,{variant:"outline",className:"text-xs text-gray-500",children:"✅ GPT-4 Tokenizer"})}),e.jsx("div",{className:"flex items-center gap-2",children:e.jsx(T,{variant:"outline",className:"text-xs text-gray-500",children:"✅ Real-time Token Counting"})}),e.jsx("div",{className:"flex items-center gap-2",children:e.jsx(T,{variant:"outline",className:"text-xs text-gray-500",children:"📝 Curated Responses"})})]}),e.jsxs(n,{onClick:()=>{x("basic"),o(!0)},className:"w-full bg-gradient-to-r from-purple-600 to-pink-600 hover:from-purple-700 hover:to-pink-700 text-white",children:[e.jsx(a,{className:"w-4 h-4 mr-2"}),"Try Basic Mode"]})]}),e.jsxs("div",{className:"bg-gradient-to-br from-blue-50 to-purple-50 dark:from-blue-950/20 dark:to-purple-950/20 rounded-2xl p-6",children:[e.jsxs("div",{className:"text-center mb-4",children:[e.jsx("div",{className:"inline-flex p-3 bg-white dark:bg-gray-800 rounded-full shadow-lg mb-3",children:e.jsx(h,{className:"w-6 h-6 text-blue-600"})}),e.jsx("h3",{className:"text-lg font-semibold mb-2",children:"AI Generation + Tokens"}),e.jsx("p",{className:"text-sm text-muted-foreground",children:"Full NLP pipeline with actual AI text generation and tokenization"})]}),e.jsxs("div",{className:"space-y-2 text-xs text-muted-foreground mb-4",children:[e.jsx("div",{className:"flex items-center gap-2",children:e.jsx(T,{variant:"outline",className:"text-xs text-gray-500",children:"✅ GPT-4 Tokenizer"})}),e.jsx("div",{className:"flex items-center gap-2",children:e.jsx(T,{variant:"outline",className:"text-xs text-gray-500",children:"🤖 DistilGPT-2 Generation"})}),e.jsx("div",{className:"flex items-center gap-2",children:e.jsx(T,{variant:"outline",className:"text-xs text-gray-500",children:"⚡ Full NLP Pipeline"})})]}),e.jsxs(n,{onClick:()=>{x("advanced"),d(!0)},className:"w-full bg-gradient-to-r from-blue-600 to-purple-600 hover:from-blue-700 hover:to-purple-700 text-white",children:[e.jsx(h,{className:"w-4 h-4 mr-2"}),"Try AI Generation"]})]})]}),e.jsx("div",{className:"mt-8 text-center",children:e.jsxs("div",{className:"space-y-3 text-sm text-muted-foreground mb-6",children:[e.jsx("p",{children:"Try asking either mode:"}),e.jsxs("div",{className:"flex flex-wrap justify-center gap-2",children:[e.jsx(T,{variant:"outline",children:'"How does tokenization work?"'}),e.jsx(T,{variant:"outline",children:'"Generate a creative response"'}),e.jsx(T,{variant:"outline",children:'"Explain the difference between modes"'}),e.jsx(T,{variant:"outline",children:'"What are Carlos\'s ML projects?"'})]})]})})]})}),e.jsx("section",{className:"py-16 px-4",children:e.jsxs("div",{className:"container mx-auto max-w-4xl",children:[e.jsx("h2",{className:"text-3xl font-bold text-center mb-12",children:"Technical Implementation"}),e.jsxs("div",{className:"grid grid-cols-1 md:grid-cols-2 gap-8",children:[e.jsxs(r,{children:[e.jsxs(i,{children:[e.jsx(l,{children:"Tokenizer Details"}),e.jsx(N,{children:"GPT-4 tokenizer specifications and capabilities"})]}),e.jsxs(p,{className:"space-y-3",children:[e.jsxs("div",{className:"flex justify-between",children:[e.jsx("span",{className:"text-sm text-muted-foreground",children:"Model:"}),e.jsx("span",{className:"text-sm font-mono",children:"Xenova/gpt-4"})]}),e.jsxs("div",{className:"flex justify-between",children:[e.jsx("span",{className:"text-sm text-muted-foreground",children:"Vocabulary Size:"}),e.jsx("span",{className:"text-sm font-mono",children:"~100k tokens"})]}),e.jsxs("div",{className:"flex justify-between",children:[e.jsx("span",{className:"text-sm text-muted-foreground",children:"Encoding:"}),e.jsx("span",{className:"text-sm font-mono",children:"BPE (Byte-Pair)"})]}),e.jsxs("div",{className:"flex justify-between",children:[e.jsx("span",{className:"text-sm text-muted-foreground",children:"Languages:"}),e.jsx("span",{className:"text-sm",children:"Multilingual"})]})]})]}),e.jsxs(r,{children:[e.jsxs(i,{children:[e.jsx(l,{children:"Performance Metrics"}),e.jsx(N,{children:"Real-time processing capabilities"})]}),e.jsxs(p,{className:"space-y-3",children:[e.jsxs("div",{className:"flex justify-between",children:[e.jsx("span",{className:"text-sm text-muted-foreground",children:"Tokenization Speed:"}),e.jsx("span",{className:"text-sm",children:"~1ms per message"})]}),e.jsxs("div",{className:"flex justify-between",children:[e.jsx("span",{className:"text-sm text-muted-foreground",children:"Memory Usage:"}),e.jsx("span",{className:"text-sm",children:"~50MB loaded"})]}),e.jsxs("div",{className:"flex justify-between",children:[e.jsx("span",{className:"text-sm text-muted-foreground",children:"Processing:"}),e.jsx("span",{className:"text-sm",children:"Client-side only"})]}),e.jsxs("div",{className:"flex justify-between",children:[e.jsx("span",{className:"text-sm text-muted-foreground",children:"Framework:"}),e.jsx("span",{className:"text-sm font-mono",children:"Transformers.js"})]})]})]})]})]})})]}),"basic"===m&&e.jsx(E,{isOpen:t,onToggle:()=>o(!t)}),"advanced"===m&&e.jsx(v,{isOpen:c,onToggle:()=>d(!c)})]})};export{M as default};
